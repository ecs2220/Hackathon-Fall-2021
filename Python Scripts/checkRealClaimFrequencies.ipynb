{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Checking Real Claim Frequencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Claim"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "df_claim_twitter = pd.read_csv(\"data/unifiedCSVs/raw_claim_twitter.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Fake\n",
    "df_claim_twitter_fake_subset = df_claim_twitter[df_claim_twitter[\"real_or_fake\"] == \"fake\"]\n",
    "\n",
    "count = df_claim_twitter_fake_subset[\"claim_id\"].value_counts()\n",
    "count = count[count >= 9]\n",
    "valid_claim_ids = count.index.tolist()[1:]\n",
    "\n",
    "# print(count)\n",
    "\n",
    "df_claim_twitter_fake_subset = df_claim_twitter_fake_subset[df_claim_twitter_fake_subset[\"claim_id\"].isin(valid_claim_ids)]\n",
    "\n",
    "print(f\"Fake subset length: {df_claim_twitter_fake_subset.shape[0]}\")\n",
    "\n",
    "# Real\n",
    "df_claim_twitter_real_subset = df_claim_twitter[df_claim_twitter[\"real_or_fake\"] == \"real\"]\n",
    "\n",
    "count = df_claim_twitter_real_subset[\"claim_id\"].value_counts()\n",
    "count = count[count >= 9]\n",
    "valid_claim_ids = count.index.tolist()\n",
    "\n",
    "# print(count[count >= 9])\n",
    "\n",
    "df_claim_twitter_real_subset = df_claim_twitter_real_subset[df_claim_twitter_real_subset[\"claim_id\"].isin(valid_claim_ids)]\n",
    "\n",
    "print(f\"Real subset length: {df_claim_twitter_real_subset.shape[0]}\")\n",
    "\n",
    "df_claim_twitter_fake_subset.append(df_claim_twitter_real_subset).to_csv(\"data/toPull/claim_twitter_ids.csv\", index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fake subset length: 235\n",
      "Real subset length: 20597\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## News"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "df_news_articles = pd.read_csv(\"data/news_with_dates.csv\")\n",
    "df_news_articles = df_news_articles.dropna(subset=['date'])\n",
    "\n",
    "news_id_list = df_news_articles[\"news_id\"].tolist()\n",
    "\n",
    "df_news_twitter = pd.read_csv(\"data/unifiedCSVs/raw_news_twitter.csv\")\n",
    "\n",
    "df_news_twitter = df_news_twitter[df_news_twitter[\"news_id\"].isin(news_id_list)]\n",
    "\n",
    "# df_claim_twitter_fake_subset = df_claim_twitter_fake_subset[df_claim_twitter_fake_subset[\"claim_id\"].isin(valid_claim_ids)]\n",
    "# df_news_twitter.shape[0]\n",
    "# df_news_twitter2\n",
    "df_news_twitter"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>date</th>\n",
       "      <th>real_or_fake</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>1300283193250246658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>1300187087421886464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>1296588646552932352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>1296234752463245313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>1290072458129584129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274876</th>\n",
       "      <td>4296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>real</td>\n",
       "      <td>1321060426206093315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274877</th>\n",
       "      <td>4296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>real</td>\n",
       "      <td>1315896649785372672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274878</th>\n",
       "      <td>4311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>real</td>\n",
       "      <td>1319572296319774720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274879</th>\n",
       "      <td>4311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>real</td>\n",
       "      <td>1316748475510542350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274880</th>\n",
       "      <td>4311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>real</td>\n",
       "      <td>1310630581349253124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248910 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        news_id  date real_or_fake             tweet_id\n",
       "0           891   NaN         fake  1300283193250246658\n",
       "1           891   NaN         fake  1300187087421886464\n",
       "2           900   NaN         fake  1296588646552932352\n",
       "3           900   NaN         fake  1296234752463245313\n",
       "4           903   NaN         fake  1290072458129584129\n",
       "...         ...   ...          ...                  ...\n",
       "274876     4296   NaN         real  1321060426206093315\n",
       "274877     4296   NaN         real  1315896649785372672\n",
       "274878     4311   NaN         real  1319572296319774720\n",
       "274879     4311   NaN         real  1316748475510542350\n",
       "274880     4311   NaN         real  1310630581349253124\n",
       "\n",
       "[248910 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Fake\n",
    "df_news_twitter_fake_subset = df_news_twitter[df_news_twitter[\"real_or_fake\"] == \"fake\"]\n",
    "\n",
    "count = df_news_twitter_fake_subset[\"news_id\"].value_counts()\n",
    "count = count[count >= 9]\n",
    "\n",
    "valid_news_ids = count.index.tolist()\n",
    "\n",
    "df_news_twitter_fake_subset = df_news_twitter_fake_subset[df_news_twitter_fake_subset[\"news_id\"].isin(valid_news_ids)]\n",
    "\n",
    "print(f\"Fake subset length: {df_news_twitter_fake_subset.shape[0]}\")\n",
    "\n",
    "# Real\n",
    "df_news_twitter_real_subset = df_news_twitter[df_news_twitter[\"real_or_fake\"] == \"real\"]\n",
    "\n",
    "count = df_news_twitter_real_subset[\"news_id\"].value_counts()\n",
    "count = count[count >= 9]\n",
    "\n",
    "valid_news_ids = count.index.tolist()\n",
    "\n",
    "df_news_twitter_real_subset = df_news_twitter_real_subset[df_news_twitter_real_subset[\"news_id\"].isin(valid_news_ids)]\n",
    "\n",
    "print(f\"Real subset length: {df_news_twitter_real_subset.shape[0]}\")\n",
    "\n",
    "df_news_twitter_fake_subset.append(df_news_twitter_real_subset).to_csv(\"data/toPull/news_twitter_ids.csv\", index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fake subset length: 15475\n",
      "Real subset length: 231292\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "72feb122fca61636127e7194cba100bbfb85a485da5e26a835360b692f4b0926"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}