{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clean Twitter IDs\n",
    "\n",
    "Only id columns\n",
    "Seperate with replies\n",
    "\n",
    "add fake or real and add date\n",
    "\n",
    "Twitter News Data:\n",
    "- news_id: int\n",
    "- tweet_id: int\n",
    "- reply_id: int\n",
    "- real_or_fake: str \"real\" or \"fake\"\n",
    "- date: (empty at first) str \"MM-DD-YYYY\"\n",
    "\n",
    "News Data\n",
    "- news_id: int \n",
    "- real_or_fake: str \"real\" or \"fake\"\n",
    "- date: (empty at first) str \"MM-DD-YYYY\"\n",
    "- type: str\n",
    "- raw_date: str\n",
    "- fact_check_url: str \n",
    "- archive: str\n",
    "- news_url: str\n",
    "- news_url2: str\n",
    "- news_url3: str\n",
    "- news_url4: str\n",
    "- news_url5: str\n",
    "- title: str\n",
    "- newstitle: str\n",
    "- content: str\n",
    "- abstract: str\n",
    "- meta_keywords: str (formatted similar to a list)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "df_claim_twitter = pd.DataFrame(columns={\"claim_id\", \"tweet_id\", \"reply_id\", \"real_or_fake\", \"date\"})\n",
    "df_claim_articles = pd.DataFrame(columns={\"claim_id\", \"real_or_fake\", \"fact_check_url\", \"news_url\", \"title\", \"date\"})\n",
    "\n",
    "df_news_twitter = pd.DataFrame(columns={\"news_id\", \"tweet_id\", \"reply_id\", \"real_or_fake\", \"date\"})\n",
    "df_news_articles = pd.DataFrame(columns={\"news_id\", \"real_or_fake\", \"date\", \"type\", \"raw_date\", \"fact_check_url\", \"archive\", \"news_url\", \"news_url2\", \"news_url3\", \"news_url4\", \"news_url5\", \"title\", \"newstitle\", \"content\", \"abstract\", \"meta_keywords\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "directory = \"data/rawFromCoAID/\"\n",
    "\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "  for filename in files:\n",
    "    filepath = subdir + os.sep + filename\n",
    "\n",
    "    if filename.endswith(\".csv\"):\n",
    "      print(filename)\n",
    "      df_from_csv = pd.read_csv(filepath)\n",
    "\n",
    "      if \"Claim\" in filename: # Claim\n",
    "        if \"tweets\" in filename:\n",
    "          df_from_csv = df_from_csv.rename(columns={\"index\": \"news_id\"})\n",
    "          df_from_csv = df_from_csv.rename(columns={\"news_id\": \"claim_id\"})\n",
    "          df_from_csv[\"real_or_fake\"] = \"real\" if \"Real\" in filename else \"fake\"\n",
    "          \n",
    "          df_claim_twitter = pd.concat([df_claim_twitter, df_from_csv])\n",
    "          \n",
    "        else:\n",
    "          df_from_csv = df_from_csv.rename(columns={\"Unnamed: 0\": \"claim_id\"})\n",
    "          df_from_csv[\"real_or_fake\"] = \"real\" if \"Real\" in filename else \"fake\"\n",
    "\n",
    "          df_claim_articles = pd.concat([df_claim_articles, df_from_csv])\n",
    "\n",
    "      else: # News\n",
    "        if \"tweets\" in filename:\n",
    "          df_from_csv = df_from_csv.rename(columns={\"index\": \"news_id\"})\n",
    "          df_from_csv[\"real_or_fake\"] = \"real\" if \"Real\" in filename else \"fake\"\n",
    "          \n",
    "          df_news_twitter = pd.concat([df_news_twitter, df_from_csv])\n",
    "          \n",
    "        else:\n",
    "          df_from_csv = df_from_csv.rename(columns={\"Unnamed: 0\": \"news_id\", \"publish_date\": \"raw_date\"})\n",
    "          df_from_csv[\"real_or_fake\"] = \"real\" if \"Real\" in filename else \"fake\"\n",
    "\n",
    "          df_news_articles = pd.concat([df_news_articles, df_from_csv])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NewsFakeCOVID-19_tweets.csv\n",
      "NewsFakeCOVID-19_tweets_replies.csv\n",
      "NewsFakeCOVID-19.csv\n",
      "ClaimRealCOVID-19_tweets.csv\n",
      "ClaimRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19.csv\n",
      "ClaimRealCOVID-19.csv\n",
      "NewsRealCOVID-19_tweets.csv\n",
      "NewsFakeCOVID-19_tweets.csv\n",
      "NewsFakeCOVID-19_tweets_replies.csv\n",
      "ClaimFakeCOVID-19.csv\n",
      "NewsFakeCOVID-19.csv\n",
      "ClaimFakeCOVID-19_tweets.csv\n",
      "ClaimRealCOVID-19_tweets.csv\n",
      "ClaimFakeCOVID-19_tweets_replies.csv\n",
      "ClaimRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19.csv\n",
      "ClaimRealCOVID-19.csv\n",
      "NewsRealCOVID-19_tweets.csv\n",
      "NewsFakeCOVID-19_tweets.csv\n",
      "NewsFakeCOVID-19_tweets_replies.csv\n",
      "ClaimFakeCOVID-19.csv\n",
      "NewsFakeCOVID-19.csv\n",
      "ClaimFakeCOVID-19_tweets.csv\n",
      "ClaimRealCOVID-19_tweets.csv\n",
      "ClaimFakeCOVID-19_tweets_replies.csv\n",
      "ClaimRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19.csv\n",
      "ClaimRealCOVID-19.csv\n",
      "NewsRealCOVID-19_tweets.csv\n",
      "NewsFakeCOVID-19_tweets.csv\n",
      "NewsFakeCOVID-19_tweets_replies.csv\n",
      "NewsFakeCOVID-19.csv\n",
      "ClaimRealCOVID-19_tweets.csv\n",
      "ClaimRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19_tweets_replies.csv\n",
      "NewsRealCOVID-19.csv\n",
      "ClaimRealCOVID-19.csv\n",
      "NewsRealCOVID-19_tweets.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "df_claim_twitter.to_csv(\"data/unifiedCSVs/raw_claim_twitter.csv\", index=False)\n",
    "df_claim_articles.to_csv(\"data/unifiedCSVs/raw_claim_articles.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "df_news_twitter.to_csv(\"data/unifiedCSVs/raw_news_twitter.csv\", index=False)\n",
    "df_news_articles.to_csv(\"data/unifiedCSVs/raw_news_articles.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "72feb122fca61636127e7194cba100bbfb85a485da5e26a835360b692f4b0926"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}